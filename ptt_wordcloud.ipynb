{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acded9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import jieba.analyse as analyse\n",
    "\n",
    "#模擬使用者讀取網頁\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.92 Safari/537.36'}\n",
    "\n",
    "# 目標網站\n",
    "url = 'https://www.pttweb.cc/hot/news/today'\n",
    "# 發出 get請求\n",
    "resp = requests.get(url, headers=headers)\n",
    "# 網頁編碼\n",
    "resp.encoding = 'utf-8'\n",
    "# 進行網頁解析\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "# 找出所有 div區塊中 帶有目標class名的元素\n",
    "divs = soup.find_all('div', 'e7-right-top-container e7-no-outline-all-descendants')\n",
    "# 新增個list存取爬下來的內容\n",
    "articles = []\n",
    "# 換個網頁爬文章內容\n",
    "root = 'https://www.ptt.cc'\n",
    "for div in divs:\n",
    "    link = div.find('a')['href']\n",
    "    title = div.find('span', 'e7-show-if-device-is-not-xs').text\n",
    "    articles.append({\n",
    "        'title':title.replace('\\u3000', ' '),\n",
    "        'link':root + link + '.html'\n",
    "    })\n",
    "for article in articles:\n",
    "    res = requests.get(article['link'], headers = {'cookie': 'over18=1;'})\n",
    "    if res.status_code == 404:\n",
    "        articles.remove(article)\n",
    "    else:\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        main = soup.find('div', id='main-content')\n",
    "        main_tag = main.find_all('div', class_='push')\n",
    "        # 新增一個位置存取文章的推文內容\n",
    "        comment = []\n",
    "\n",
    "        for i in main_tag:\n",
    "            # 如果沒有推文就跳過\n",
    "            if not i.find('span', 'push-tag'):\n",
    "                continue\n",
    "            # 把: 標點符號替換掉    \n",
    "            push_content = i.find('span', 'push-content').text.replace(': ',\"\")\n",
    "            # 推文內容存入\n",
    "            comment.append(push_content)\n",
    "    \n",
    "        article['content'] = comment\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big.txt')\n",
    "\n",
    "# 抓前十篇熱門新聞製作文字雲\n",
    "for article in articles[:10]:\n",
    "    content_text = article['content']\n",
    "    content_list = \" \".join(content_text)\n",
    "    tfidf_fre = jieba.analyse.extract_tags(content_list, topK=100, withWeight=True, allowPOS=(),withFlag=True)\n",
    "    \n",
    "    # 把分析完的詞頻輸出成字典\n",
    "    count_dic = {}\n",
    "    for i in range(len(tfidf_fre)):\n",
    "        count_dic[tfidf_fre[i][0]] = tfidf_fre[i][1]\n",
    "    # 把字典交給wordcloud做成文字雲\n",
    "    myWordClode = WordCloud(\n",
    "                       width=1200, # 圖的寬度\n",
    "                       height=600,      # 圖的長度\n",
    "                       background_color=\"black\",  # 背景顏色 預設是白色\n",
    "                       colormap=\"Dark2\",\n",
    "                       font_path='SourceHanSansTW-Regular.otf' # 輸出字體 必須將字體的檔案放在同個資料夾下\n",
    "                        ).fit_words(count_dic)\n",
    "    # 用PIL顯示文字雲\n",
    "    plt.figure(figsize=(8, 6), dpi=100) \n",
    "    plt.imshow(myWordClode)\n",
    "    plt.axis(\"off\")\n",
    "    print(article['title'])\n",
    "    print(article['link'])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
